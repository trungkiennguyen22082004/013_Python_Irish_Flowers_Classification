{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIẢI QUYẾT BÀI TOÁN PHÂN LOẠI HOA IRIS SỬ DỤNG MẠNG LƯỚI THẦN KINH SÂU\n",
    "\n",
    "## GIỚI THIỆU\n",
    "\n",
    "Trong bài viết này, chúng ta hãy cùng tìm hiểu về những điều cơ bản nhất về Mạng lưới thần kinh sâu (Deep Neural Network), cũng như một trong những bài toán kinh điển sử dụng nó - Phân loại hoa Iris (IRIS Flowers Classification)\n",
    "\n",
    "**Mục tiêu của bài viết:**\n",
    "\n",
    "- Giới thiệu về các thành phần mạng lưới thần kinh sâu\n",
    "- Xây dựng một mạng lưới thần kinh sâu từ A đến Z\n",
    "- Sự dụng mạng lưới thần kinh sâu đã tạo để giải quyết bài toán kinh điển Phân loại hoa Iris\n",
    "\n",
    "**Chú thích**\n",
    "- Ký hiệu các chứ cái in hoa là các ma trận: $X$, $A$, $Z$, $W$\n",
    "- Ký hiệu các chữ cái in thường là các vector với kích thước (<số tự nhiên>, 1): $x$, $a$, $z$, $w$, $b$\n",
    "- Ký hiệu $[l]$ đại diện cho lớp thứ $l^{th}$\n",
    "    - Ký hiệu $L$ là số lớp của mạng thần kinh (Số lớp ẩn + 1)\n",
    "    - Ký hiệu $n^{l}$ là số neuron trong lớp thứ l\n",
    "    - Ký hiệu $a^{[L]}$ là hàm kích hoạt (activation function) của lớp thứ $l^{th}$\n",
    "- Ký hiệu $(i)$ đại diện cho thí dụ thứ $i^{th}$\n",
    "    - Ký hiệu $n^(i)$ là ví dụ thứ $i^{th}$ của tập training\n",
    "- Ký hiệu $i$ đại diện cho vị trí thứ $i^{th}$ của 1 vector\n",
    "    - Ký hiệu $a^{[l]}_i$ là phần tử thứ $i^{th}$ của hàm kích hoạt của lớp thứ $l^{th}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MỤC LỤC\n",
    "- [1 - Tổng quan về Mạng lưới thần kinh sâu](#1---tổng-quan-về-mạng-lưới-thần-kinh-sâu)\n",
    "- [2 - Giới thiệu về bài toán Phân loại hoa IRIS](#2---giới-thiệu-về-bài-toán-phân-loại-hoa-iris)\n",
    "- [3 - Xây dựng mạng lưới thần kinh sâu](#3---xây-dựng-mạng-lưới-thần-kinh-sâu)\n",
    "    - [3.1 - Thư viện được sử dụng](#31---thư-viện-được-sử-dụng)\n",
    "    - [3.2 - Xây dựng lớp tuyến tính](#32---xây-dựng-lớp-tuyến-tính)\n",
    "        - [3.2.1 - Khởi tạo lớp tuyến tính](#321---khởi-tạo-lớp-tuyến-tính)\n",
    "        - [3.2.2 - Xây dựng hàm cho quá trình Lan truyền tiến của lớp tuyến tính](#322---xây-dựng-hàm-cho-quá-trình-lan-truyền-tiến-của-lớp-tuyến-tính)\n",
    "        - [3.2.3 - Xây dựng hàm cho quá trình Lan truyền ngược của lớp tuyến tính](#323---xây-dựng-hàm-cho-quá-trình-lan-truyền-ngược-của-lớp-tuyến-tính)\n",
    "    - [3.3 - Xây dựng lớp kích hoạt Softmax](#33---xây-dựng-lớp-kích-hoạt-softmax)\n",
    "        - [3.3.1 - Khởi tạo lớp kích hoạt Softmax](#331---khởi-tạo-lớp-kích-hoạt-softmax)\n",
    "        - [3.3.2 - Xây dựng hàm cho quá trình Lan truyền tiến của lớp kích hoạt Softmax](#332---xây-dựng-hàm-cho-quá-trình-lan-truyền-tiến-của-lớp-kích-hoạt-softmax)\n",
    "        - [3.3.3 - Xây dựng hàm cho quá trình Lan truyền ngược của lớp kích hoạt Softmax](#333---xây-dựng-hàm-cho-quá-trình-lan-truyền-ngược-của-lớp-kích-hoạt-softmax)\n",
    "    - [3.4 - Xây dựng lớp ẩn hoàn chỉnh](#34---xây-dựng-lớp-ẩn-hoàn-chỉnh)\n",
    "        - [3.4.1 - Khởi tạo lớp ẩn](#341---khởi-tạo-lớp-ẩn)\n",
    "        - [3.4.2 - Xây dựng hàm cho quá trình Lan truyền tiến của lớp ẩn](#342---xây-dựng-hàm-cho-quá-trình-lan-truyền-tiến-của-lớp-ẩn)\n",
    "        - [3.4.3 - Xây dựng hàm cho quá trình Lan truyền ngược của lớp ẩn](#343---xây-dựng-hàm-cho-quá-trình-lan-truyền-ngược-của-lớp-ẩn)\n",
    "    - [3.5 - Xây dựng mạng thần kinh sâu với số lượng lớp ẩn tùy chọn](#35---xây-dựng-mạng-thần-kinh-sâu-với-số-lượng-lớp-ẩn-tùy-chọn)\n",
    "        - [3.5.1 - Khởi tạo mạng thần kinh sâu](#351---khởi-tạo-mạng-thần-kinh-sâu)\n",
    "        - [3.5.2 - Xây dựng hàm cho quá trình dự đoán của mạng](#352---xây-dựng-hàm-cho-quá-trình-dự-đoán-của-mạng) \n",
    "- [4 - Xử lý đầu vào](#4---xử-lý-đầu-vào)\n",
    "    - [4.1 - Các thư viện sẽ sử dụng](#41---các-thư-viện-sẽ-sử-dụng)\n",
    "    - [4.2 - Đọc và xử lý dữ liệu](#42---đọc-và-xử-lý-dữ-liệu)\n",
    "- [5 - Training và Testing](#5---training-và-testing)\n",
    "- [6 - Kết luận](#6---kết-luận)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "### 1 - Tổng quan về Mạng lưới thần kinh sâu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Về cơ bản, việc xây dựng các loại mạng lưới thần kinh sâu đều được lấy cảm hứng từ cấu trúc và chức năng của bộ não con người. Chúng được phát triển nhằm mục đích nhận diện các mẫu dữ liệu từ thế giới bên ngoài, học hỏi từ kinh nghiệm, từ đó giúp xử lý nhiều vấn đề từ đơn giản đến phức tạp. Hiện nay, các lĩnh vực phổ biến có áp dụng Mạng lưới thần kinh sâu bao gồm Thị giác máy tính (Computer Vision), Xử lý ngôn ngữ tự nhiên (Natural Language Processing), Phát hiện bất thường (Anomaly Dectection), Nhận diện giọng nói (Speech Recognition), .... Kể từ đây, bài viết sẽ chỉ nhắc đến khái niệm Mạng lưới thần kinh tiêu chuẩn (Standard Neural Network), vốn là mô hình mạng lưới thần kinh sâu cơ bản nhất.\n",
    "\n",
    "Một mạng lưới thần kinh sâu đơn giản có cấu trúc như sau:\n",
    "- Lớp đầu vào (Input layer): Lớp này có chức năng nhận dữ liệu ban đầu, thường là các số liệu. Các dạng đầu vào khác như hình ảnh, âm thanh, văn bản có thể được chuyển đổi thành như ma trận số liệu theo những phương pháp khác nhau.\n",
    "- (Các) lớp ẩn (Hidden layer(s)): (Các) lớp ẩn là những lớp trung gian trong mạng lưới thần kinh sâu, đóng vai trò chuyển tiếp giữa lớp đầu vào và lớp đầu ra. Mỗi lớp ẩn bao gồm một số lượng nhất định các neurons, có nhiệm vụ xử lý và phân tích dữ liệu bằng cách sử dụng một loạt các công thức toán học, đồng thời trích xuất những đặc trưng của dữ liệu đầu vào.\n",
    "- Lớp đầu ra (Output layer): Lớp này có chức năng đưa ra các đầu ra cuối cùng (giá trị dự đoán) bằng cách sử dụng các đặc trưng đã được trích xuất. Tùy thuộc vào kiểu dữ liệu mong muốn, lớp này có thể có một hoặc nhiều neurons. Mục tiêu của mạng lưới thần kinh sâu là tối thiểu hóa sai số giữa giá trị dự đoán và giá trị thực tế.\n",
    "\n",
    "Mỗi một lớp ẩn trong mạng sẽ có các thành phần sau đây:\n",
    "- Trọng số - Weight ($W$): Kết nối giữa một lớp ẩn đến một lớp ẩn kế tiếp được điều chỉnh bởi các trọng số của lớp ẩn đó. Chúng thể hiện mức độ quan trọng của đầu vào và đầu ra của các neurons.\n",
    "- Ngưỡng - Bias($b$): Là các giá trị độc lập dùng để điều chỉnh độ lệch của đầu ra của các neurons.\n",
    "- Hàm kích hoạt - Activation function: Đây là một hàm phi tuyến tính như ReLU, Sigmoid, Softmax, .... Nếu các lớp ẩn trong một mạng lưới thần kinh sâu chỉ sử dụng các trọng số và ngưỡng để tính toán thì mạng đó chỉ là một phương trình tuyến tính khổng lồ (linear function), và nó hoàn toàn không thể biển diễn được các vấn đề phức tạp. Do vậy, các hàm kích hoạt phi tuyến tính được áp dụng nhằm mô hình hóa các mối liên hệ phức tạp hơn.\n",
    "Từ đó, với $X$ là giá trị đầu vào, $Z$ là giá trị đầu ra của mỗi lớp ẩn, ta có thể xây dựng phương trình lớp ẩn như sau:\n",
    "$$ Z = activationFunction(WX + b)$$\n",
    "\n",
    "**Lan truyền tiến (Forward Propagation)**\n",
    "- Trong quá trình này, giá trị đầu vào sẽ được sử dụng để tính toán giá trị đầu ra của các lớp trung gian, cái mà tiếp tục được sử dụng để tính toán giá trị đầu ra của các lớp trung gian tiếp theo trong mạng. Cuối cùng, giá trị đầu ra của lớp đầu ra được gọi là giá trị dự đoán.\n",
    "    - Để đo sự khác biệt giữa giá trị dự đoán và giá trị thực tế, ta sẽ sử dụng hàm mất mát (Loss function). Việc lựa chọn hàm mất mát sẽ tùy thuộc vào bài toán mà chúng ta cần giải quyết.\n",
    "\n",
    "**Lan truyền ngược (Backward Propagation)**\n",
    "- Ở đây, (các) sai số giữa giá trị dự đoán và giá trị thực tế được điều chỉnh các tham số của từng lớp ẩn (trọng số và ngưỡng), nhằm tối thiểu hóa sai số.\n",
    "    - Đầu tiên, tính toán giá trị đầu hàm của hàm mất mát theo giá trị đầu ra dự đoán của mạng.\n",
    "    - Từ đó, sử dụng dây chuyền trong tích phân (Chain rule), để tính giá trị đạo hàm của hàm mất mát theo tham số của từng lớp ẩn\n",
    "    - Sau khi đã tính toán được các giá trị đạo hàm này, chúng ta sử dụng phương pháp suy giảm độ dốc (Gradient Descent), để cập nhật giá trị của các tham số\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "### 2 - Giới thiệu về bài toán Phân loại hoa IRIS\n",
    "\n",
    "Bài toán phân loại hoa IRIS là một trong những bài toán kinh điển trong lĩnh vực học máy (Machine Learning). Mục tiêu của bài toán là phân loại hoa vào một trong ba loại: Iris setosa, Iris versicolor và Iris virginica, dựa trên các đặc trưng của chúng.\n",
    "\n",
    "Các đặc trưng của hoa Iris được thu thập và công bố lần đầu tiên vào năm 1936, bởi nhà khoa học người Anh Ronald Fisher. Chúng bao gồm: \n",
    "- Chiều dài đài hoa (sepal length)\n",
    "- Chiều rộng đài hoa (sepal width)\n",
    "- Chiều dài cánh hoa (petal length)\n",
    "- Chiều rộng cánh hoa (petal width)\n",
    "\n",
    "Dữ liệu về hoa được sử dụng được tải xuống từ [Kaggle](https://www.kaggle.com/datasets/arshid/iris-flower-dataset), bao gồm 150 mẫu về hoa iris, với 50 mẫu từ mỗi loài trong số ba loài trên.\n",
    "\n",
    "Bài toán này là một bài toán phân phối xác suất với 3 giá trị, do vậy hàm kích hoạt cho lớp đầu ra được sử dụng sẽ là hàm Softmax:\n",
    "$$\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{L} e^{z_j}}$$\n",
    "\n",
    "trong đó:\n",
    "- $z$ là giá trị đầu ra của lớp tuyến tính từ lớp ẩn của mạng\n",
    "- $e$ là cơ số của logarit tự nhiên (số Euler)\n",
    "\n",
    "Đối với các lớp ẩn khác, các hàm kích hoạt khác như ReLu, Sigmoid có thể được sử dụng. Tuy nhiên, để tránh rắc rối trong việc thực hiện, ta sẽ áp dụng hàm Softmax cho tất cả các lớp ẩn trong mạng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "### 3 - Xây dựng mạng lưới thần kinh sâu\n",
    "\n",
    "Để xây dựng mạng lưới thần kinh sâu một cách dễ dàng và dễ hiểu, chúng ta sẽ áp dụng các nguyên tắc trong lập trình hướng đối tượng (Object-oriented programming). Theo đó, mỗi lớp trong mạng sẽ biểu hiện bởi class `StandardLayer`. Lớp này sẽ bao gồm một lớp tuyến tính, và một lớp kích hoạt Sigmoid, được biểu hiện bằng 2 class tương ứng `Linear` và `Sigmoid`. Tất cả các class này đều được thực hiện các phương thức tương ứng cho quá trình lan truyền tiến và ngược, đó là `forward` và `backward`. Ngoài ra, hàm `backward` của class `Linear` cũng sẽ được thực hiện phương pháp suy giảm độ dốc để cập nhật các tham số. \n",
    "\n",
    "Sau đó, một class sẽ biểu diễn cho mạng, gọi là `NeuralNetwork`. Class này sẽ có các phương thức như sau:\n",
    "- `predict` dùng cho quá trình training và testing mô hình\n",
    "- `computeCost` dùng để tính hàm mất mát sau quá trình lan truyền tiến\n",
    "- `computeCostGradient` dùng để tính đạo hàm của hàm mất mát trên giá trị dự đoán (đầu ra) của mạng, để phục vụ cho quá trình lan truyền ngược\n",
    "\n",
    "<a name='3-1'></a>\n",
    "#### 3.1 - Thư viện được sử dụng\n",
    "\n",
    "Thư viện [numpy](www.numpy.org) sẽ được sử dụng, dùng để thực hiện các tính toán giữa các ma trận trong cả hai quá trình lan truyền tiến và ngược của ma trận. Phiên bản numpy 1.26.4 được khuyến khích sử dụng trong quá trình thực hiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "#### 3.2 - Xây dựng lớp tuyến tính\n",
    "\n",
    "<a name='3-2-1'></a>\n",
    "##### 3.2.1 - Khởi tạo lớp tuyến tính\n",
    "\n",
    "**Tham số cho lớp tuyến tính**:\n",
    "Mỗi một lớp sẽ có một số lượng các inputs (cũng là số neurons của lớp trước đó), và một số lượng các outputs (cũng là số neurons của lớp hiện tại). Chúng ta cần khởi tạo các tham số của một lớp, đó là các trọng số ($W$), và các ngưỡng ($b$) dựa vào các dữ liệu trên.\n",
    "- Đối với các trọng số, ta sẽ khởi tạo một ma trận ngẫu nhiên có kích thước (<số neurons lớp trước>, <số neurons lớp hiện tại>), sử dụng hàm `random.rand` của thư viện `numpy`. \n",
    "- Đối với các ngưỡng, độ lệch có thể bằng 0 vào thời điểm ban đầu, nên ta sẽ khởi tạo một vector với các phần tử bằng 0 với kích thước (<số neurons lớp hiện tại>, 1), sử dụng hàm `zeros` của thư viện `numpy`\n",
    "\n",
    "**Tốc độ học**:\n",
    "Tốc độ học cũng là một thuộc tính cần thiết của lớp tuyến tính, khi mà nó sẽ được sử dụng trong quá trình cập nhất tham số với Suy giảm độ dốc.\n",
    "Nó sẽ là một tham số khi ta khởi tạo đối tượng `Linear` cho lớp tuyến tính, nên ta chỉ đơn giản là gán giá trị cho thuộc tính `self.learningRate`.\n",
    "\n",
    "**Bộ nhớ tạm**:\n",
    "Một thuộc tính khác sẽ được khởi tạo để lưu trữ đầu vào của lớp, các tham số trước khi cập nhật, gọi là `self.cache`, sẽ được sử dụng cho quá trình lan truyền ngược của lớp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self, inputDimension, outputDimension, learningRate=3e-3):\n",
    "        \n",
    "        # inputDimension means the number of units in the previous hidden layer, or the input size of the input layer (if that is the previous layer)\n",
    "        # outputDimension also means the number of units in the current layer\n",
    "        \n",
    "        self.W = np.random.rand(outputDimension, inputDimension) * 0.01\n",
    "        self.b = np.zeros((outputDimension, 1))\n",
    "        \n",
    "        self.cache = None\n",
    "        \n",
    "        self.learingRate = learningRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2-2'></a>\n",
    "##### 3.2.2 - Xây dựng hàm cho quá trình Lan truyền tiến của lớp tuyến tính\n",
    "\n",
    "Ta chỉ đơn giản áp dùng hàm tuyến tính cho quá trình lan truyền tiến của lớp:\n",
    "$$ Z = WA + b$$\n",
    "\n",
    "Ta cần xây dựng phép nhân ma trận để tính $Z$\n",
    "\n",
    "Ví dụ, cho:\n",
    "- Số lượng mẫu của đầu vào: 4\n",
    "- Số lượng neurons của lớp trước: 3\n",
    "- Số lượng neurons của lớp hiện tại: 2\n",
    "- $A$ với kích thước (3, 4):\n",
    "$$ A = \\begin{bmatrix}\n",
    "    a_{00} & a_{01} & a_{02} & a_{03} \\\\\n",
    "    a_{10} & a_{11} & a_{12} & a_{13} \\\\\n",
    "    a_{20} & a_{21} & a_{22} & a_{23}\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "- $W$ với kích thước (3, 4):\n",
    "$$\n",
    "   W = \\begin{bmatrix} \n",
    "    w_{00} & w_{01} & w_{02} \\\\\n",
    "    w_{10} & w_{11} & w_{12} \n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "- $b$ với kích thước (2, 1):\n",
    "$$\n",
    "   b = \\begin{bmatrix} \n",
    "    b_{0} \\\\\n",
    "    b_{1} \n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "$Z$ sẽ được tính như sau:\n",
    "$$\n",
    "   Z = \\begin{bmatrix} \n",
    "    w_{00} * a_{00} + w_{01} * a_{10} + w_{02} * a_{20} + b_{0} & w_{00} * a_{01} + w_{01} * a_{11} + w_{02} * a_{21} + b_{0} & w_{00} * a_{02} + w_{01} * a_{12} + w_{02} * a_{22} + b_{0} & w_{00} * a_{03} + w_{01} * a_{13} + w_{02} * a_{23} + b_0 \\\\\n",
    "    w_{10} * a_{00} + w_{11} * a_{10} + w_{12} * a_{20} + b_{1} & w_{10} * a_{01} + w_{11} * a_{11} + w_{12} * a_{21} + b_{1} & w_{10} * a_{02} + w_{11} * a_{12} + w_{12} * a_{22} + b_{1} & w_{10} * a_{03} + w_{11} * a_{13} + w_{12} * a_{23} + b_1\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "Để thực hiện phép nhân ma trận, ta có thể tính bằng cách sử dụng 2 vòng lặp `for`, hoặc sử dụng hàm `dot` của thư viện `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearForward(self, A):\n",
    "        \n",
    "    # A is the output from the previous hidden layer with the shape of (<number of units in that previous layer>, <number of examples>)\n",
    "        \n",
    "    # Cache is stored for computing the backward pass efficiently\n",
    "    self.cache = (A, self.W, self.b)\n",
    "        \n",
    "    # Calculate properly:\n",
    "    (previousLayerDimension, numberOfExamples) = A.shape\n",
    "        \n",
    "    currentLayerDimension = self.W.shape[0]\n",
    "        \n",
    "    Z = np.zeros((currentLayerDimension, numberOfExamples))\n",
    "        \n",
    "    for i in range(currentLayerDimension):\n",
    "        for j in range(numberOfExamples):\n",
    "            dot = 0\n",
    "            for k in range(previousLayerDimension):\n",
    "                dot += A[k, j] * self.W[i, k]\n",
    "                    \n",
    "            # Add the bias\n",
    "            Z[i, j] = dot + self.b[i]\n",
    "        \n",
    "    # Calculate simply using numpy matrix multiplication:\n",
    "    # Z = np.dot(self.W, A) + self.b\n",
    "        \n",
    "    return Z\n",
    "\n",
    "Linear.forward = linearForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2-3'></a>\n",
    "##### 3.2.3 - Xây dựng hàm cho quá trình Lan truyền ngược của lớp tuyến tính\n",
    "\n",
    "Ý tưởng của Mạng thần kinh sâu là sử dụng phương pháp suy giảm độ sâu, dựa trên giá trị đạo hàm của hàm mất mát theo các giá trị tham số của mỗi lớp trong mạng, qua đó cập nhật những tham số đó để Mô hình trở nên đúng hơn. Đầu tiên, chúng ta sẽ tính giá trị đạo hàm của hàm mất mát theo các giá trị tham số của lớp.\n",
    "\n",
    "##### a. Tính giá trị đạo hàm của hàm mất mát theo các giá trị tham số của lớp.\n",
    "\n",
    "Theo lớp tuyến tính, ta đã đề cập công thức sau ở phần 3.2.2: $$Z = W A + b\\tag{3.2.3-a}$$\n",
    "\n",
    "Cho $deltaZ$, đại lượng mà giả sử đã được tính toán trước đó, là giá trị đạo hàm của hàm mất mát theo giá trị đầu ra của lớp. Nói cách khác, $deltaZ = \\frac{\\partial \\mathcal{L} }{\\partial Z}$. Ta cần tính:\n",
    "- $deltaW = \\frac{\\partial \\mathcal{L} }{\\partial W}$ là giá trị đạo hàm của hàm mất mát theo trọng số $W$ của lớp.\n",
    "- $deltab = \\frac{\\partial \\mathcal{L} }{\\partial b}$ là giá trị đạo hàm của hàm mất mát theo ngưỡng $b$ của lớp.\n",
    "- Ta cũng sẽ tính giá trị đạo hàm của hàm mất mát theo đầu vào $A$ của lớp, ký hiệu là $deltaA = \\frac{\\partial \\mathcal{L} }{\\partial A}$, nhằm lưu trữ vào bộ nhớ tạm để có thể sử dụng cho các bước kế tiếp.\n",
    "\n",
    "Để tính các giá trị đạo hàm trên, ta sẽ làm quen với một quy tắc rất hữu ích trong tích phân, đó là quy tắc dây chuyền (Chain rule):\n",
    "\n",
    "Cho hai hàm số $f$ và $g$, thì đạo hàm của hàm hợp $f(g(x))$ theo x được tính như sau: $$\\frac{d}{dx}[f(g(x))] = f'(g(x)) \\cdot g'(x)$$\n",
    "Đơn giản hơn, ta có thể viết lại công thức trên như sau: \n",
    "$$\\frac{\\partial f }{\\partial x} = \\frac{\\partial f }{\\partial g} \\frac{\\partial g }{\\partial x}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "***Bây giờ ta sẽ áp dụng luật này để tính các giá trị đạo hàm đã liệt kê, bắt đầu với $deltaW$:***\n",
    "$$\\frac{\\partial \\mathcal{L} }{\\partial W} = \\frac{\\partial \\mathcal{L} }{\\partial Z} \\frac{\\partial Z }{\\partial W} \\tag{3.2.3-b}$$\n",
    "\n",
    "Mặt khác, từ công thức (3.2.3-a), ta có thể tính giá trị đạo hàm của đầu ra của lớp theo trọng số tương ứng ($\\frac{\\partial Z }{\\partial W}$) như sau:\n",
    "$$\\frac{\\partial Z }{\\partial W} = \\frac{\\partial (W A + b) }{\\partial W} = A \\tag{3.2.3-c}$$\n",
    "\n",
    "Từ (3.2.3-c), ta có thể biến đổi (3.2.3-b) thành:\n",
    "$$deltaW = deltaZ * A\\tag{3.2.3-d}$$\n",
    "\n",
    "***Tương tự, đối với giá trị $deltab$, ta có:***\n",
    "$$ \\frac{\\partial Z }{\\partial b} = \\frac{\\partial (W A + b) }{\\partial b} = 1 $$\n",
    "$$ \\frac{\\partial \\mathcal{L} }{\\partial b} = \\frac{\\partial \\mathcal{L} }{\\partial Z} \\frac{\\partial Z }{\\partial b} <=> deltab = deltaZ \\tag{3.2.3-e}$$\n",
    "\n",
    "***Và với $deltaA$:***\n",
    "\n",
    "$$ \\frac{\\partial Z }{\\partial A} = \\frac{\\partial (W A + b) }{\\partial A} = W $$\n",
    "$$ \\frac{\\partial \\mathcal{L} }{\\partial A} = \\frac{\\partial \\mathcal{L} }{\\partial Z} \\frac{\\partial Z }{\\partial A} <=> deltaA = deltaZ * W \\tag{3.2.3-f}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearBackward(self, deltaZ):\n",
    "        \n",
    "    # Get the previous input\n",
    "    A = self.cache[0]\n",
    "        \n",
    "    # deltaW is the gradient of the cost with respect to the weights W of the current linear layer (dZ / dW)\n",
    "    deltaW = np.dot(deltaZ, A.transpose())\n",
    "        \n",
    "    # deltab is the gradient of the cost with respect to the biases b of the current linear layer (dZ / db)\n",
    "    deltab = np.sum(deltaZ, axis=1)\n",
    "        \n",
    "    # deltaA is the gradient of the cost with respect to the input of the current linear layer (which is also the output of the previous layer)\n",
    "    deltaA = np.dot(self.W.transpose(), deltaZ)\n",
    "        \n",
    "    # Update the weights and biases\n",
    "    self.updateParamaters(deltaW=deltaW, deltab=deltab)\n",
    "        \n",
    "    return (deltaA, deltaW, deltab)\n",
    "\n",
    "Linear.backward = linearBackward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Cập nhật các tham số của lớp bằng Suy giảm độ dốc\n",
    "\n",
    "**Giới thiệu về Suy giảm độ dốc**\n",
    "\n",
    "<div style=\"text-align: center;\"><img src=\"images/gradient_descent_illustration_1.png\" style=\"width:585px;height:555px;\"></div>\n",
    "<caption><center><b>Ảnh 3.2.3-a. Một đồ thị hàm số điển hình. Được lấy từ <a>https://machinelearningcoban.com/2017/01/12/gradientdescent/#2-gradient-descent-cho-h%c3%a0m-1-bi%e1%ba%bfn</a></b></center></caption><br>\n",
    "\n",
    "Trong ảnh trên, điểm màu xanh lục $x*$ là một cực tiểu của hàm số f, và cũng là điểm làm cho hàm số này đạt giá trị nhỏ nhất. Tại điểm này, giá trị đạo hàm của hàm số đã cho sẽ bị triệu tiêu (bằng 0). Giá trị đạo hàm của các điểm lân cận bên trái của điểm này bé hơn hoặc bằng 0, và giá trị đạo hàm của các điểm lân cận bên phải của nó sẽ lớn hơn hoặc bằng 0.\n",
    "\n",
    "<br>\n",
    "\n",
    "Từ đó, ta có thể nhận thấy, x càng xa $x*$ về bên phải, thì giá trị đạo hàm tương ứng càng lớn hơn 0, khi đó ta cần **giảm** giá trị x một đoạn tỉ lệ thuận với giá trị đạo hàm của nó:\n",
    "$$ x_{i+1} = x_{i} - f'(x_{i}) $$\n",
    "\n",
    "Ngược lại, khi x càng xa $x*$ về bên trái, thì giá trị đạo hàm tương ứng càng bé hơn 0, khi đó ta cần **tăng** giá trị x một đoạn tỉ lệ thuận với giá trị đạo hàm của nó:\n",
    "$$ x_{i+1} = x_{i} - f'(x_{i}) $$\n",
    "\n",
    "Áp dụng vào bài toán, ta có thể cập nhật các tham số của lớp tuyến tính như sau:\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } deltaW^{[l]} \\tag{3.2.3-f}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } deltab^{[l]} \\tag{3.2.3-g}$$\n",
    "\n",
    "với \n",
    "- $deltaW$ và $deltab$ là các giá trị đạo hàm của hàm mất mát theo các tham số đã được tính ở (3.2.3-d) và (3.2.3-e)\n",
    "- $\\alpha$ là tốc độ học\n",
    "\n",
    "Ta sẽ chọn một hàm mất mát sao cho \"dấu\" của các giá trị đạo hàm sẽ phù hợp để tìm giá trị cực tiểu, để ta chỉ cần chọn tốc độ học mà không cần phải xét dấu của chúng, đó là Binary Cross-Entropy Loss. Ta sẽ nói cụ thể ở các phần sau, nhìn chung, ở đây ta chỉ cần một giá trị $\\alpha$ hợp lý. Nếu giá trị này quá nhỏ thì bước điều chỉnh của các tham số sẽ nhỏ, rất đến tốn nhiều thời gian để cập nhật các tham số đến với các giá trị gần đúng. Tuy nhiên, nếu giá trị này quá lớn thì ta sẽ bị \"bỏ lỡ\" giá trị cực tiểu của hàm mất mát, dẫn tới sự sai lệch của mô hình. Sau khi thực hiện một vài thử nghiệm, tôi đã lấy giá trị $3^{e}-3$ cho tốc độ học.\n",
    "\n",
    "Sau đây ta sẽ sử dụng các công thức (3.2.3-f) và (3.2.3-g). Khi thực hiện, ta có thể nhân một cách đơn giản giữa một số thực với một ma trận numpy, hoặc sử dụng những vòng lặp for để hiểu bản chất hơn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParamaters(self, deltaW, deltab):\n",
    "        \n",
    "    # self.W -= self.learingRate * deltaW\n",
    "    # self.b -= self.learingRate * deltab\n",
    "        \n",
    "    for i in range(0, self.W.shape[0]):\n",
    "        for j in range(0, self.W.shape[1]):\n",
    "            self.W[i][j] -= self.learingRate * deltaW[i][j]\n",
    "    for i in range(0, len(self.b)):\n",
    "        self.b[i] -= self.learingRate * deltab[i]\n",
    "        \n",
    "Linear.updateParamaters = updateParamaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "#### 3.3 - Xây dựng lớp kích hoạt Softmax\n",
    "\n",
    "Như đã nói ở trên, để có thể mô hình hóa những vấn đề phức tạp, một mạng thần kinh sâu chỉ bao gồm các lớp tuyến tính là bất khả thi. Do vậy, các lớp kích hoạt, với nòng cốt là những hàm kích hoạt như ReLU, Sigmoid, Softmax, ..., được áp dụng vào việc tính toán giá trị đầu ra của các lớp ẩn.\n",
    "\n",
    "Đối với bài toán Phân loại hoa Iris nói riêng và bài toán Phân loại nhiều lớp - Multiclassification nói chung, ta sẽ sử dụng lớp Softmax cho lớp đầu ra của mạng. Các lớp ẩn khác có thể sử dụng những hàm kích hoạt khác, tuy nhiên để đơn giản, ta sẽ chỉ sử dụng hàm Softmax cho tất cả các lớp.\n",
    "\n",
    "**Hàm Softmax**\n",
    "Trong mục 2 tôi đã trình bày công thức của hàm Softmax. Tuy nhiên, nó thực sự là gì? Và tại sao nó lại hiệu quả khi giải quyết các bài toàn dạng Phân loại nhiều lớp như Phân loại hoa Iris?\n",
    "\n",
    "Nhắc lại một chút về công thức của hàm Softmax: \n",
    "$$\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{L} e^{z_j}} \\tag{3.3-a}$$\n",
    "\n",
    "trong đó:\n",
    "- $z$ là giá trị đầu ra của lớp tuyến tính từ lớp ẩn của mạng\n",
    "- $e$ là cơ số của logarithm tự nhiên (số Euler)\n",
    "\n",
    "Giả sử, ta có một ma trận $Z$ là giá trị đầu ra có kích thước $mxn$, với $m$ là số lượng tập mẫu, $n$ là số lượng các kết quả dự đoán có thể có:\n",
    "\n",
    "$$ Z = \\begin{bmatrix}\n",
    "    z_{00} & z_{01} & z_{02} & z_{03} & \\cdots & z_{0n} \\\\\n",
    "    z_{10} & z_{11} & z_{12} & z_{13} & \\cdots & z_{1n} \\\\\n",
    "    z_{20} & z_{21} & z_{22} & z_{23} & \\cdots & z_{2n} \\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "    z_{m0} & z_{m1} & z_{m2} & z_{m3} & \\cdots & z_{mn}\n",
    "    \\end{bmatrix}\\;\\;\\;\\;\\;\n",
    "$$\n",
    "\n",
    "Hàm Softmax sẽ chuyển đổi các giá trị này thành một ma trận đầu ra $Y$:\n",
    "\n",
    "$$ Y = \\begin{bmatrix}\n",
    "    \\sigma(z_{00}) & \\sigma(z_{01}) & \\sigma(z_{02}) & \\sigma(z_{03}) & \\cdots & \\sigma(z_{0n}) \\\\\n",
    "    \\sigma(z_{10}) & \\sigma(z_{11}) & \\sigma(z_{12}) & \\sigma(z_{13}) & \\cdots & \\sigma(z_{1n}) \\\\\n",
    "    \\sigma(z_{20}) & \\sigma(z_{21}) & \\sigma(z_{22}) & \\sigma(z_{23}) & \\cdots & \\sigma(z_{2n}) \\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "    \\sigma(z_{m0}) & \\sigma(z_{m1}) & \\sigma(z_{m2}) & \\sigma(z_{m3}) & \\cdots & \\sigma(z_{mn})\n",
    "    \\end{bmatrix}\\;\\;\\;\\;\\;\n",
    "$$\n",
    "\n",
    "Dễ thấy, trong mỗi một vector của $Y$ là $y_{j} = \\begin{bmatrix} \\sigma(z_{j0}) & \\sigma(z_{j1}) & \\sigma(z_{j2}) & \\sigma(z_{j3}) & \\cdots & \\sigma(z_{jn}) \\end{bmatrix}\\; $, các phần tử luông nằm trong khoảng $[0, 1]$, và tổng của các phẩn tử luôn bằng 1. Đặc điểm nay giúp mô hình hóa các bài toán cần đưa ra dự đoán dưới dạng phân phối xác suất, với mỗi phần tử sẽ là tỉ lệ của mỗi đặc tính tương ứng mà bài toán yêu cầu phải phân loại.\n",
    "\n",
    "Với bài toán Phân loại hoa, ta cần dự đoán xác suất của một mẫu hoa là Iris setosa, Iris versicolor hay Iris virginica ($n$ = 3). Ứng với mẫu hoa thứ $j$, sử dụng hàm Softmax với Lớp đầu ra có kích thước là 3, kết quả giá trị đầu ra dự đoán thứ $j$ sẽ là một vector có 3 phần tử, thí dụ là $y_{j} = \\begin{bmatrix} 0.25 & 0.4 & 0.3 \\end{bmatrix}\\;$, sẽ mang ý nghĩa tỉ lệ để mẫu hoa thứ $j$ là Iris setosa, Iris versicolor, và Iris virginica lần lượt là 25%, 40% và 35%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3-1'></a>\n",
    "##### 3.3.1 - Khởi tạo lớp kích hoạt Softmax\n",
    "\n",
    "Các hàm kích hoạt cơ bản như Softmax không có các tham số như lớp tuyến tính, nên việc khởi tạo lớp khá đơn giản. Ở đây, ta chỉ cần khởi tạo một thuộc tính cho bộ nhớ tạm dùng trong các quá trình lan truyền tiến và ngược của lớp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.cache = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3-2'></a>\n",
    "##### 3.3.2 -  Xây dựng hàm cho quá trình Lan truyền tiến của lớp kích hoạt Softmax\n",
    "\n",
    "Bây giờ ta sẽ áp dụng công thức (3.3-a) để xây dựng hàm cho quá trình Lan truyền tiến của lớp kích hoạt Softmax, thông qua các bước sau:\n",
    "\n",
    "Cho đầu vào của lớp là ma trận đầu ra của lớp tuyến tính $A$ (với $m$ là số tập mẫu),\n",
    "\n",
    "$$ A = \\begin{bmatrix}\n",
    "    a_{00} & a_{01} & a_{02} & \\cdots & a_{0m} \\\\\n",
    "    a_{10} & a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n",
    "    a_{20} & a_{21} & a_{22} & \\cdots & a_{2m}\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "- Tính lũy thừa của $A$ với bậc là số Euler ($e$) (là tử số của (3.3-a))\n",
    "\n",
    "$$ expA = \\begin{bmatrix}\n",
    "    expA_{00} = e^{a_{00}} & expA_{01} = e^{a_{01}} & expA_{02} = e^{a_{02}} & \\cdots & expA_{0m} = e^{a_{0m}} \\\\\n",
    "    expA_{10} = e^{a_{10}} & expA_{11} = e^{a_{11}} & expA_{12} = e^{a_{12}} & \\cdots & expA_{1m} = e^{a_{1m}} \\\\\n",
    "    expA_{20} = e^{a_{20}} & expA_{21} = e^{a_{21}} & expA_{22} = e^{a_{22}} & \\cdots & expA_{2m} = e^{a_{2m}}\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "- Tính tổng của các phần tử giá trị đầu ra, (là mẫu số của (3.3-a))\n",
    "\n",
    "$$ expASum = \\begin{bmatrix}\n",
    "    expASum_{0} = e^{a_{00}} + e^{a_{10}} + e^{a_{20}} \\\\\n",
    "    expASum_{1} = e^{a_{01}} + e^{a_{11}} + e^{a_{21}} \\\\\n",
    "    \\cdots \\\\\n",
    "    expASum_{m} = e^{a_{0m}} + e^{a_{1m}} + e^{a_{2m}}\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "- Tính đầu ra của lớp Softmax:\n",
    "\n",
    "$$ Z = \\begin{bmatrix}\n",
    "    z_{00} = \\frac{expA_{00}}{expASum_{0}} & z_{01} = \\frac{expA_{01}}{expASum_{0}} & z_{02} = \\frac{expA_{02}}{expASum_{0}} & \\cdots & z_{0m} = \\frac{expA_{0m}}{expASum_{0}} \\\\\n",
    "    z_{10} = \\frac{expA_{10}}{expASum_{1}} & z_{11} = \\frac{expA_{11}}{expASum_{1}} & z_{12} = \\frac{expA_{12}}{expASum_{1}} & \\cdots & z_{1m} = \\frac{expA_{1m}}{expASum_{1}} \\\\\n",
    "    z_{20} = \\frac{expA_{20}}{expASum_{2}} & z_{21} = \\frac{expA_{21}}{expASum_{2}} & z_{22} = \\frac{expA_{22}}{expASum_{2}} & \\cdots & z_{2m} = \\frac{expA_{2m}}{expASum_{2}}\n",
    "    \\end{bmatrix}\\;\\;\\;\n",
    "$$\n",
    "\n",
    "Ta có thể thực hiện các nhiệm vụ trên một cách đơn giản thông qua các toán tử và hàm có sẵn của ma trận trong thư viện Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxForward(self, A):\n",
    "        \n",
    "    # Cache is stored for computing the backward pass efficiently\n",
    "    self.cache = A\n",
    "    \n",
    "    # Compute the exponential values\n",
    "    expA = np.exp(A)\n",
    "        \n",
    "    # Compute the sum of exponential values for each example\n",
    "    expASum = np.sum(expA, axis=0, keepdims=True)\n",
    "        \n",
    "    # Compute the softmax output\n",
    "    Z = expA / expASum\n",
    "        \n",
    "    return Z\n",
    "\n",
    "Softmax.forward = softmaxForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3-3'></a>\n",
    "##### 3.3.3 -  Xây dựng hàm cho quá trình Lan truyền ngược của lớp kích hoạt Softmax\n",
    "\n",
    "Với hàm này, ta sẽ nhận đầu vào $deltaZ$ là giá trị đạo hàm của hàm mất mát theo giá trị đầu ra của lớp kích hoạt Softmax. \n",
    "<br>\n",
    "Trong quá trình lan truyền ngược, chúng ta cần phải đi ngược từ lớp kích hoạt trước rồi mới đến lớp tuyến tính. Trong phần (3.2.3.a), ta thấy giá trị đạo hàm của hàm mất mát theo giá trị đầu ra của lớp tuyến tính đã được \"cho trước\" như là một tham số trong quá trình lan truyền ngược, có nghĩa là ta phải tính giá trị đó ở bước này. Giá trị đầu ra của lớp tuyến tính cũng là giá trị đầu vào của lớp kích hoạt, do đó ta sẽ tính $deltaA$ là giá trị đạo hàm của hàm mất mát theo giá trị đầu vào của lớp kích hoạt Softmax, để có thể phục vụ cho quá trình lan truyền ngược của lớp tuyến tính được thực hiện sau đó.\n",
    "\n",
    "Áp dụng luật dây chuyền đã được đề cập ở trên, ta có:\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{L} }{\\partial A} = \\frac{\\partial \\mathcal{L} }{\\partial Z} \\frac{\\partial A }{\\partial Z} \\tag{3.3.3-a} $$\n",
    "với \n",
    "- $\\frac{\\partial \\mathcal{L} }{\\partial A} = deltaA$ là giá trị đạo hàm của hàm mất mát theo giá trị đầu vào của lớp kích hoạt Softmax\n",
    "- $\\frac{\\partial \\mathcal{L} }{\\partial Z} = deltaZ$ là giá trị đạo hàm của hàm mất mát theo giá trị đầu ra của lớp kích hoạt Softmax\n",
    "- $\\frac{\\partial A }{\\partial Z} = gradientZtoA$ là giá trị đạo hàm của đầu vào của lớp kích hoạt Softmax theo đầu ra của lớp kích hoạt Softmax\n",
    "\n",
    "Ta cần phải xây dựng công thức để tính $gradientZtoA$, có nghĩa là ta phải tính đạo hàm của hàm Softmax (3.3-a) theo $A$\n",
    "<br>\n",
    "\n",
    "*Trước mắt, ta sẽ lấy giá trị đầu ra của lớp kích hoạt ($A$) thông qua thuộc tính bộ nhớ tạm (`cache`)*\n",
    "<br>\n",
    "*Giờ ta sẽ tính đạo hàm $gradientZToA$:* Ta có công thức đạo hàm quen thuộc sau: Cho $f$ và $g$ là hai hàm số theo x, $h$ được định nghĩa là $h(x) = \\frac{f(x)}{g(x)}$, thì đạo hàm $h'(x)$ sẽ được tính như sau:\n",
    "$$\\frac{{d}}{{dx}}\\left(\\frac{{f(x)}}{{g(x)}}\\right) = \\frac{{f'(x) \\cdot g(x) - f(x) \\cdot g'(x)}}{{(g(x))^2}}$$\n",
    "với\n",
    "- $f'(x)$ là đạo hàm của $f(x)$ theo $x$\n",
    "- $g'(x)$ là đạo hàm của $g(x)$ theo $x$\n",
    "\n",
    "**Áp dụng công thức này, với một vài phép biến đổi đơn giản, ta có được công thức sau:**\n",
    "\n",
    "$$ \\frac{\\partial \\text{softmax}(\\mathbf{a})_i}{\\partial a_k} = \\frac{{e^{a_k} \\cdot (\\sum_{j=1}^{n} e^{a_j} - e^{a_k})}}{{(\\sum_{j=1}^{n} e^{a_j})^2}} $$ \n",
    "\n",
    "<br>\n",
    "\n",
    "Với công thức này, ta sẽ thực hiện trong Python:\n",
    "- Tính giá trị $expA$ \n",
    "- Tính giá trị các tổng của các phần tử khác trong $expA$ ngoài giá trị $exp_{k}$, tức là $\\sum_{j=1}^{n} e^{a_j} - e^{a_k}$ (ký hiệu là $otherSumsOfExpA$)\n",
    "- Tính giá trị các tổng của tất cả các phần tử: $expA$ + $otherSumsOfExpA$\n",
    "\n",
    "<br>\n",
    "\n",
    "Từ đây, ta có thể biến đổi công thức (3.3.3-a) như sau:\n",
    "$$ deltaA = deltaZ * \\frac{expA * otherSumsOfExpA}{(expA + otherSumsOfExpA)^2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxBackward(self, deltaZ):\n",
    "\n",
    "    # Get the previous input\n",
    "    A = self.cache\n",
    "    \n",
    "    # Calculate e^(a_i)\n",
    "    expA = np.exp(A)\n",
    "        \n",
    "    # Calculate Other sums of exp function of A = Exp Sum - e^(a_i)\n",
    "    otherSumsOfExpA = np.zeros(shape=expA.shape, dtype=expA.dtype)\n",
    "        \n",
    "    for i in range(expA.shape[0]):\n",
    "        for j in range(expA.shape[1]):\n",
    "            otherSumsOfExpA[i, j] = np.sum(expA[(i+1)%(expA.shape[0]), j]) + np.sum(expA[(i+2)%(expA.shape[0]), j])\n",
    "        \n",
    "    # Compute the gradient of the input of the softmax layer with respect to the output of the softmax layer\n",
    "    gradientZToA = (expA * otherSumsOfExpA) / ((expA + otherSumsOfExpA) ** 2)   \n",
    "        \n",
    "    # Compute the gradient of the cost with respect to the input of the softmax layer\n",
    "    deltaA = deltaZ * gradientZToA\n",
    "\n",
    "    return deltaA\n",
    "\n",
    "Softmax.backward = softmaxBackward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-4'></a>\n",
    "#### 3.4 - Xây dựng lớp ẩn hoàn chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-4-1'></a>\n",
    "##### 3.4.1 - Khởi tạo lớp ẩn\n",
    "\n",
    "*P/s: Chúng ta đã tìm hiểu về cách xây dựng lớp kích hoạt Softmax ở phần trước, tại sao không thử xây dựng lớp cho các hàm kích hoạt khác (như ReLU, Sigmoid, ...)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLayer:\n",
    "    \n",
    "    def __init__(self, inputDimension, outputDimension, learningRate, activationFunction):\n",
    "        \n",
    "        self.linearLayer = Linear(inputDimension, outputDimension, learningRate)\n",
    "        \n",
    "        self.activationFunction = activationFunction\n",
    "        \n",
    "        self.activationFunctionLayer = None\n",
    "        if activationFunction == \"Softmax\":\n",
    "            self.activationFunctionLayer = Softmax()\n",
    "        # elif activationFunction == \"ReLU\":\n",
    "        #     self.activationFunctionLayer = ReLu()\n",
    "        # elif activationFunction == \"Softmax\":\n",
    "        #     self.activationFunctionLayer = Softmax()\n",
    "        else:\n",
    "            self.activationFunctionLayer = Softmax()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-4-2'></a>\n",
    "##### 3.4.2 -  Xây dựng hàm cho quá trình Lan truyền tiến của lớp ẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, A):\n",
    "        \n",
    "    Z = self.linearLayer.forward(A)\n",
    "    Z = self.activationFunctionLayer.forward(Z)\n",
    "        \n",
    "    return Z      \n",
    "\n",
    "StandardLayer.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-4-3'></a>\n",
    "##### 3.4.3 -  Xây dựng hàm cho quá trình Lan truyền ngược của lớp ẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, deltaZ):\n",
    "        \n",
    "    # deltaZ is the gradient of the cost with the respect to the post-activation output\n",
    "    # deltaHidden is the gradient of the cost with the respect to the post-linear function output\n",
    "        \n",
    "    deltaHidden = self.activationFunctionLayer.backward(deltaZ)\n",
    "    (deltaA, deltaW, deltab) = self.linearLayer.backward(deltaZ)\n",
    "        \n",
    "    return (deltaA, deltaW, deltab)\n",
    "\n",
    "StandardLayer.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-5'></a>\n",
    "#### 3.5 - Xây dựng mạng thần kinh sâu với số lượng lớp ẩn tùy chọn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-5-1'></a>\n",
    "##### 3.5.1 -  Khởi tạo mạng thần kinh sâu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputDimension, hiddenDimensions, outputDimension, learningRate, activationFunctions=None):\n",
    "        \n",
    "        self.dimensions = [inputDimension] + hiddenDimensions\n",
    "        \n",
    "        # By default, activation function for all hidden layers is Softmax\n",
    "        if activationFunctions is None:\n",
    "            activationFunctions = [\"Softmax\"] * (len(hiddenDimensions) + 1)\n",
    "        elif len(activationFunctions) < hiddenDimensions:\n",
    "            activationFunctions += [\"Softmax\"] * (len(hiddenDimensions) - len(activationFunctions) + 1)\n",
    "        \n",
    "        # Initialize the hidden layers\n",
    "        self.layers = []\n",
    "        for i in range(0, len(hiddenDimensions)):\n",
    "            self.layers.append(StandardLayer(inputDimension=self.dimensions[i], outputDimension=self.dimensions[i + 1], learningRate=learningRate, activationFunction=activationFunctions[i]))\n",
    "            \n",
    "        # Initialize the final layer\n",
    "        self.finalLayer = StandardLayer(inputDimension=self.dimensions[-1], outputDimension=outputDimension, learningRate=learningRate, activationFunction=activationFunctions[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-5-2'></a>\n",
    "##### 3.5.2 -  Xây dựng hàm cho quá trình dự đoán của mạng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, A, Y, training=True):\n",
    "        \n",
    "    # Y is 3the actual label\n",
    "        \n",
    "    hidden = A\n",
    "        \n",
    "    # Forward pass through the layers\n",
    "    index = 0\n",
    "    for layer in self.layers:\n",
    "            \n",
    "        index += 1\n",
    "            \n",
    "        hidden = layer.forward(hidden)\n",
    "            \n",
    "    # AL is the output of the forward propagation\n",
    "    AL = self.finalLayer.forward(hidden)\n",
    "        \n",
    "    # Calculate the cost\n",
    "        \n",
    "    cost = self.computeCost(AL, Y)\n",
    "    \n",
    "    if training:\n",
    "        # If the process is training, the we apply the backpropagation:\n",
    "        #   Calculate the gradient of the cost with respect to the scores\n",
    "        deltaAL = self.computeCostGradient(AL, Y)\n",
    "            \n",
    "        #   Backward pass to the final layer\n",
    "        (deltaAL, _, _) = self.finalLayer.backward(deltaAL)\n",
    "            \n",
    "        #   Backward pass to the remaining layers\n",
    "        index = 0\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "\n",
    "            index += 1                \n",
    "            \n",
    "            (deltaAL, _, _) = self.layers[i].backward(deltaAL)\n",
    "            \n",
    "    return AL, cost\n",
    "\n",
    "NeuralNetwork.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(self, AL, Y):\n",
    "        \n",
    "    # Y the actual label. Y.shape = (1, m)\n",
    "    # Get the number of examples\n",
    "    m = Y.shape[1]\n",
    "        \n",
    "    # Calculate the cross-entropy cost\n",
    "    epsilon = 1e-15\n",
    "    AL = np.clip(AL, epsilon, 1 - epsilon)\n",
    "    binaryCrossEntropy = - (Y * np.log(AL) + (1 - Y) * np.log(1 - AL))\n",
    "        \n",
    "    cost = np.mean(binaryCrossEntropy)\n",
    "        \n",
    "    # cost = (-1 / m) * (np.dot(Y, (np.log(AL)).transpose()) + np.dot((1 - Y), (np.log(1 - AL)).transpose()))\n",
    "        \n",
    "    # cost = np.squeeze(cost)\n",
    "        \n",
    "    # print(\"\\n==============================COMPUTE COST===============================\")\n",
    "    # print(\"Cost: {}\".format(cost))\n",
    "        \n",
    "    return cost\n",
    "\n",
    "NeuralNetwork.computeCost = computeCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostGradient(self, AL, Y):\n",
    "        \n",
    "        # Get the number of examples\n",
    "    m = Y.shape[1]\n",
    "        \n",
    "        # Cost formula:\n",
    "        # J = (-1 / m) * [(y_1 * log(a_1) + (1 - y_1) * log (1 - a_1)) + (y_2 * log(a_2) + (1 - y_2) * log (1 - a_2)) + ... + (y_m * log(a_m) + (1 - y_m) * log (1 - a_m))]\n",
    "        # So, foreach pair of (a_i, y_i), the gradient of the cost with respect to a_i is that:                             \n",
    "        # J' =  (-1 / m) * [(const)' + ((y_i * log(a_i) + (1 - y_i) * log (1 - a_i)))' ]\n",
    "        #    =  (-1 / m) * [0 + (y / a) + (-(1 - y) / (1 - a))]     \n",
    "        #    =  (-1 / m) * (y - a) / [a * (1 - a)]\n",
    "        \n",
    "        # deltaAL is the gradient of the cost with respect to AL\n",
    "        # deltaAL = (-1 / m) * (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "        # deltaAL = (-1 / m) * ((Y / AL) - ((1 - Y) / (1 - AL)))\n",
    "    epsilon = 1e-15\n",
    "    AL = np.clip(AL, epsilon, 1 - epsilon)\n",
    "    deltaAL = - ((Y / AL) + (1 - Y) / (1 - AL)) / m\n",
    "        \n",
    "    return deltaAL\n",
    "\n",
    "NeuralNetwork.computeCostGradient = computeCostGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "### 4 - Xử lý đầu vào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "#### 4.1 - Các thư viện sẽ sử dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "#### 4.2 - Đọc và xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class Data:\n",
    "    \n",
    "    def __init__(self, datafileName, testProportion=0.5):\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.data = pd.read_csv(filepath_or_buffer=\"{}\".format(datafileName))\n",
    "        \n",
    "        # Extract features and target variable\n",
    "        self.x = self.data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "        self.y = self.data['species'].values\n",
    "        \n",
    "        self.xTrain, self.xTest, self.yTrain, self.yTest = train_test_split(self.x, self.y, test_size=testProportion)\n",
    "        \n",
    "        # With one-hot encoding, each output will be represented as a binary vector:\n",
    "        #   Iris-setosa: [1, 0, 0]\n",
    "        #   Iris-versicolor: [0, 1, 0]\n",
    "        #   Iris-virginica: [0, 0, 1]\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.encodedYTrain = encoder.fit_transform(self.yTrain.reshape(-1, 1))\n",
    "        self.encodedYTest = encoder.transform(self.yTest.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "### 5 - Training và Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_8824\\1008367034.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Z[i, j] = dot + self.b[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Epoch [1/24], Cost: 0.636576705410108\n",
      "\n",
      "========================================================================\n",
      "Epoch [2/24], Cost: 0.6365344187611521\n",
      "\n",
      "========================================================================\n",
      "Epoch [3/24], Cost: 0.6364926671392342\n",
      "\n",
      "========================================================================\n",
      "Epoch [4/24], Cost: 0.6364514432606853\n",
      "\n",
      "========================================================================\n",
      "Epoch [5/24], Cost: 0.6364107399524889\n",
      "\n",
      "========================================================================\n",
      "Epoch [6/24], Cost: 0.6363705501503358\n",
      "\n",
      "========================================================================\n",
      "Epoch [7/24], Cost: 0.6363308668967178\n",
      "\n",
      "========================================================================\n",
      "Epoch [8/24], Cost: 0.636291683339059\n",
      "\n",
      "========================================================================\n",
      "Epoch [9/24], Cost: 0.6362529927278903\n",
      "\n",
      "========================================================================\n",
      "Epoch [10/24], Cost: 0.636214788415056\n",
      "\n",
      "========================================================================\n",
      "Epoch [11/24], Cost: 0.6361770638519608\n",
      "\n",
      "========================================================================\n",
      "Epoch [12/24], Cost: 0.6361398125878507\n",
      "\n",
      "========================================================================\n",
      "Epoch [13/24], Cost: 0.6361030282681293\n",
      "\n",
      "========================================================================\n",
      "Epoch [14/24], Cost: 0.6360667046327084\n",
      "\n",
      "========================================================================\n",
      "Epoch [15/24], Cost: 0.6360308355143914\n",
      "\n",
      "========================================================================\n",
      "Epoch [16/24], Cost: 0.6359954148372897\n",
      "\n",
      "========================================================================\n",
      "Epoch [17/24], Cost: 0.63596043661527\n",
      "\n",
      "========================================================================\n",
      "Epoch [18/24], Cost: 0.6359258949504334\n",
      "\n",
      "========================================================================\n",
      "Epoch [19/24], Cost: 0.6358917840316244\n",
      "\n",
      "========================================================================\n",
      "Epoch [20/24], Cost: 0.6358580981329695\n",
      "\n",
      "========================================================================\n",
      "Epoch [21/24], Cost: 0.6358248316124445\n",
      "\n",
      "========================================================================\n",
      "Epoch [22/24], Cost: 0.6357919789104701\n",
      "\n",
      "========================================================================\n",
      "Epoch [23/24], Cost: 0.6357595345485356\n",
      "\n",
      "========================================================================\n",
      "Epoch [24/24], Cost: 0.6357274931278486\n",
      "\n",
      "Test Cost: 0.6374427893045067\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = Data(datafileName=\"IRIS.csv\")\n",
    "\n",
    "# Create an instance of the Neural Network\n",
    "#   Number of input features\n",
    "inputDimension = data.xTrain.shape[1]  \n",
    "#   Number of units in each hidden layer\n",
    "hiddenDimensions = [5, 5, 5] \n",
    "#   Number of output classes\n",
    "outputDimension = data.encodedYTrain.shape[1]  \n",
    "#   Learning rate\n",
    "learningRate = 0.01\n",
    "\n",
    "dnn = NeuralNetwork(inputDimension=inputDimension, hiddenDimensions=hiddenDimensions, outputDimension=outputDimension, learningRate=learningRate)\n",
    "\n",
    "numberOfEpoches = 24\n",
    "\n",
    "for epoch in range(0, numberOfEpoches):\n",
    "    # Forward propagation\n",
    "    _, cost = dnn.predict(data.xTrain.T, data.encodedYTrain.T)\n",
    "    \n",
    "    print(\"\\n========================================================================\")\n",
    "    print(\"Epoch [{}/{}], Cost: {}\".format(epoch + 1, numberOfEpoches, cost))\n",
    "        \n",
    "predictedValues, testCost = dnn.predict(data.xTest.T, data.encodedYTest.T, training=False)\n",
    "predictedValues = predictedValues.transpose()\n",
    "\n",
    "print(\"\\nTest Cost: {}\".format(testCost))\n",
    "\n",
    "decodedPredictedValues = []\n",
    "for i in range(0, predictedValues.shape[0]):\n",
    "    predictedValue = predictedValues[i]\n",
    "    \n",
    "    maxValue = max(predictedValue)\n",
    "    \n",
    "    if maxValue == predictedValue[0]:\n",
    "        decodedPredictedValues.append(\"Iris-setosa\") \n",
    "    elif maxValue == predictedValue[1]:\n",
    "        decodedPredictedValues.append(\"Iris-versicolor\") \n",
    "    else:\n",
    "        decodedPredictedValues.append(\"Iris-virginicas\")\n",
    "        \n",
    "decodedPredictedValues = np.array(decodedPredictedValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "### 6 - Kết luận"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
